{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATA_602_Kalman_Filter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QQbV2DSRcXG"
      },
      "source": [
        "**Kalman Filter**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqT5bAnaQ8-r"
      },
      "source": [
        "First, I initialized the State matrix with values he provided. I also initialized P as the Estimation Covariance matrix, with error terms that correspond to the variance of the x position and x velocity, specific to the estimates.\n",
        "Then, for each observation that was provided, I iterate through a series of processes to update the state matrix with values provided by the Kalman filter.\n",
        "First, I make a prediction of where the plane will be in the next time step. This prediction is simply based on the previous position and velocity, with an acceleration parameter that adjusts the velocity. The A matrix in the prediction2d function updates the previous state based on the time that has elapsed. The B matrix translates the acceleration into an adjustment to the position and velocity. The formula 1/2 time squared is used to find a distance given an acceleration.\n",
        "Then, I updated the Process / Estimation Covariance matrix to the next time step, predicting it forward. The operation adds a time step to the matrix, subsequently updating the variance of the distance error. The A matrix is similar to the one used in predicting the State matrix values. Since Professor Biezen eliminated the off-diagonal values, I did the same.\n",
        "Calculating the Kalman gain involved calculating the covariance matrix for the observation errors, and using it to compare with the process covariance matrix. In the problem, there’s probably more matrix rotation than what’s required, but I believe it’s meant to make the formula invariant to different matrix sizes. There is no division in matrix operations, so to find the ratio I used the dot product with the inverse of what would otherwise be the denominator.\n",
        "Notice that in matrix format, the Kalman gain is a matrix of the same dimension as the inputs, and along the diagonal are weights that adjust the observed position and velocity. The lower the weights, the lower the model trusts the observations compared to the predictions.\n",
        "With the newly calculated Kalman gain, I used it to weigh the difference between the observation data with the prediction, which was then used to update the state matrix. I also used the Kalman gain to update the process covariance matrix.\n",
        "I did that as many times as observations that were provided, and got a result that is somewhere between the observation data and predictive model, which is exactly what one should expect from using the Kalman filter. My exact results were slightly different than Professor Biezen, but note that he did commit a number of errors in his calculations and did not do a full run through of all the observations, so I’m confident my calculations were more accurate.\n",
        "Source: James Teow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48cwvCTYQ5KK",
        "outputId": "0361b159-fc9c-43f0-f836-2aec0dd5f719"
      },
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "\n",
        "x_observations = np.array([4000, 4260, 4550, 4860, 5110])\n",
        "v_observations = np.array([280, 282, 285, 286, 290])\n",
        "\n",
        "z = np.c_[x_observations, v_observations]\n",
        "\n",
        "# Initial Conditions\n",
        "a = 2  # Acceleration\n",
        "v = 280\n",
        "t = 1  # Difference in time\n",
        "\n",
        "# Process / Estimation Errors\n",
        "error_est_x = 20\n",
        "error_est_v = 5\n",
        "\n",
        "# Observation Errors\n",
        "error_obs_x = 25  # Uncertainty in the measurement\n",
        "error_obs_v = 6\n",
        "\n",
        "def prediction2d(x, v, t, a):\n",
        "    A = np.array([[1, t],\n",
        "                  [0, 1]])\n",
        "    X = np.array([[x],\n",
        "                  [v]])\n",
        "    B = np.array([[0.5 * t ** 2],\n",
        "                  [t]])\n",
        "    X_prime = A.dot(X) + B.dot(a)\n",
        "    return X_prime\n",
        "\n",
        "\n",
        "def covariance2d(sigma1, sigma2):\n",
        "    cov1_2 = sigma1 * sigma2\n",
        "    cov2_1 = sigma2 * sigma1\n",
        "    cov_matrix = np.array([[sigma1 ** 2, cov1_2],\n",
        "                           [cov2_1, sigma2 ** 2]])\n",
        "    return np.diag(np.diag(cov_matrix))\n",
        "\n",
        "\n",
        "# Initial Estimation Covariance Matrix\n",
        "P = covariance2d(error_est_x, error_est_v)\n",
        "A = np.array([[1, t],\n",
        "              [0, 1]])\n",
        "\n",
        "# Initial State Matrix\n",
        "X = np.array([[z[0][0]],\n",
        "              [v]])\n",
        "n = len(z[0])\n",
        "\n",
        "for data in z[1:]:\n",
        "    X = prediction2d(X[0][0], X[1][0], t, a)\n",
        "    # To simplify the problem\n",
        "    # set off-diagonal terms to 0.\n",
        "    P = np.diag(np.diag(A.dot(P).dot(A.T)))\n",
        "\n",
        "    # Calculating the Kalman Gain\n",
        "    H = np.identity(n)\n",
        "    R = covariance2d(error_obs_x, error_obs_v)\n",
        "    S = H.dot(P).dot(H.T) + R\n",
        "    K = P.dot(H).dot(inv(S))\n",
        "\n",
        "    # Reshape the new data into the measurement space.\n",
        "    Y = H.dot(data).reshape(n, -1)\n",
        "\n",
        "    # Update the State Matrix\n",
        "    # Combination of the predicted state, measured values, covariance matrix and Kalman Gain\n",
        "    X = X + K.dot(Y - H.dot(X))\n",
        "\n",
        "    # Update Process Covariance Matrix\n",
        "    P = (np.identity(len(K)) - K.dot(H)).dot(P)\n",
        "\n",
        "print(\"Kalman Filter State Matrix:\\n\", X)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kalman Filter State Matrix:\n",
            " [[5127.05898493]\n",
            " [ 288.55147059]]\n"
          ]
        }
      ]
    }
  ]
}